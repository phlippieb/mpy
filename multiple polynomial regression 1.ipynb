{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting db connection...\n",
      "getting db cursor...\n",
      "db ready.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from termcolor import colored\n",
    "import sys\n",
    "\n",
    "from results import psos, benchmarks\n",
    "from results.flc.ruggedness import fem_0_1 as fem0_1_results, \\\n",
    "    fem_0_01 as fem0_01_results\n",
    "from results.flc.neutrality import pn as pn_results, \\\n",
    "    lsn as lsn_results\n",
    "from results.flc.gradients import g_avg as g_avg_results, \\\n",
    "    g_dev as g_dev_results\n",
    "from results.flc.funnels import dm as dm_results\n",
    "from results.flc.deception import fdc as fdc_results\n",
    "from results.flc.searchability import fci_soc as fci_soc_results, \\\n",
    "    fci_cog as fci_cog_results, \\\n",
    "    fci_sigma as fci_sigma_results\n",
    "from results import drocs as droc_results\n",
    "from util.chunks import chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "\n",
    "pso_names = psos.all_names\n",
    "swarm_size = 25\n",
    "benchmark_names = benchmarks.all_names\n",
    "benchmark_names = sorted(benchmark_names)\n",
    "num_iterations = 2000\n",
    "num_experiments = 30\n",
    "\n",
    "flcs = {\n",
    "    'fem0_1': fem0_1_results,\n",
    "    'fem0_01': fem0_01_results,\n",
    "    'pn': pn_results,\n",
    "    'lsn': lsn_results,\n",
    "    'g_avg': g_avg_results,\n",
    "    'g_dev': g_dev_results,\n",
    "    'dm': dm_results,\n",
    "    'fdc': fdc_results,\n",
    "    'fci_cog': fci_cog_results,\n",
    "    'fci_soc': fci_soc_results,\n",
    "    'fci_sigma': fci_sigma_results\n",
    "}\n",
    "flc_names = flcs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data getter helpers\n",
    "\n",
    "def get_flcs(flc_name, benchmark_name):\n",
    "    # Get the measure function for the given name\n",
    "    flc_measure = flcs[flc_name]\n",
    "    \n",
    "    # Determine which dimensionality to use\n",
    "    D = 5\n",
    "    benchmark = benchmarks.get(benchmark_name)\n",
    "    if not benchmark.is_dimensionality_valid(D):\n",
    "        D = 2\n",
    "    \n",
    "    # Get the results for each experiment\n",
    "    results = []\n",
    "    for e in range(num_experiments):\n",
    "        result = flc_measure.get(benchmark_name, D, e)\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRoCs\n",
    "\n",
    "droc_dict = {}\n",
    "for pso_name in pso_names:\n",
    "    pso_dict = {}\n",
    "    for benchmark_name in benchmark_names:\n",
    "        D = 5\n",
    "        benchmark = benchmarks.get(benchmark_name)\n",
    "        if not benchmark.is_dimensionality_valid(D):\n",
    "            D = 2\n",
    "\n",
    "        droc_vals = []\n",
    "        for e in range(num_experiments):\n",
    "            droc = droc_results.get(\n",
    "                pso_name, swarm_size, benchmark_name, D, num_iterations, e)\n",
    "            droc_vals.append(droc)\n",
    "        pso_dict[benchmark_name] = droc_vals\n",
    "    droc_dict[pso_name] = pso_dict\n",
    "droc_df = pd.DataFrame(droc_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing zakharov                    \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Only look at Gbest PSO (for now!)\n",
    "pso_name = 'gbest_pso'\n",
    "\n",
    "# The results\n",
    "X_raw = {}\n",
    "\n",
    "for benchmark_name in benchmark_names:\n",
    "    progress_msg = '\\rProcessing ' + benchmark_name\n",
    "    sys.stdout.write('\\r                                       ')\n",
    "    sys.stdout.write(progress_msg)\n",
    "    sys.stdout.flush\n",
    "    \n",
    "    # The results for this benchmark function, in list format.\n",
    "    X = pd.Series()\n",
    "    \n",
    "    # Get the mean DRoC value for this benchmark name:\n",
    "    drocs = droc_df[pso_name][benchmark_name]\n",
    "    droc_mean = np.average(drocs)\n",
    "    X = X.append(pd.Series({'DRoC': droc_mean}))\n",
    "    \n",
    "    # Each FLC\n",
    "    for flc_name in flcs.keys():\n",
    "        flc_measures = get_flcs(flc_name, benchmark_name)\n",
    "        flc_measures_mean = np.average(flc_measures)\n",
    "        X = X.append(pd.Series({flc_name: flc_measures_mean}))\n",
    "    \n",
    "    # Save the series for this benchmark function to the results.\n",
    "    X_raw[benchmark_name] = X\n",
    "\n",
    "print ''\n",
    "print 'Done.'\n",
    "data = pd.DataFrame(X_raw)\n",
    "data = data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs and outputs\n",
    "\n",
    "input_names = [\n",
    "    'dm',\n",
    "    'lsn',\n",
    "    'fdc',\n",
    "    'fci_sigma',\n",
    "    'fem0_01',\n",
    "    'fem0_1',\n",
    "    'g_avg',\n",
    "    'fci_soc',\n",
    "    'g_dev',\n",
    "    'pn',\n",
    "    'fci_cog'\n",
    "]\n",
    "output_name = 'DRoC'\n",
    "\n",
    "X = data[input_names]\n",
    "y = data[output_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a fitting pipeline.\n",
    "\n",
    "# Params:\n",
    "degree = 2\n",
    "\n",
    "# Components etc\n",
    "pf = PolynomialFeatures(degree=degree)\n",
    "lm = linear_model.LinearRegression()\n",
    "pipeline = Pipeline([\n",
    "    ('pf', pf),\n",
    "    ('lm', lm)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "[(1.2380370340014935e-10, '1'), (-128.41013263614343, 'x0'), (66.769719060803112, 'x1'), (-204.91277908233718, 'x2'), (284.92563124911629, 'x3'), (-356.21374568977689, 'x4'), (60.314019219165573, 'x5'), (-790.15878287081534, 'x6'), (-201.77033726794974, 'x7'), (379.42371815070697, 'x8'), (24.165876823902796, 'x9'), (17.765522417847137, 'x10'), (163.11076602111018, 'x0^2'), (-15.385081762407051, 'x0 x1'), (-234.71376765664678, 'x0 x2'), (-74.271030631395377, 'x0 x3'), (-169.53357099348207, 'x0 x4'), (-84.310251167169909, 'x0 x5'), (18.868323516156345, 'x0 x6'), (-284.31110318365933, 'x0 x7'), (675.17273679186746, 'x0 x8'), (-5.7844674415118291, 'x0 x9'), (-164.2507320761855, 'x0 x10'), (0.46859737201474982, 'x1^2'), (52.5477518009886, 'x1 x2'), (1.4629506170887028, 'x1 x3'), (55.066377783406715, 'x1 x4'), (47.415608603321679, 'x1 x5'), (183.17547835275249, 'x1 x6'), (59.385715023823806, 'x1 x7'), (133.75472909518837, 'x1 x8'), (0.17307311118644261, 'x1 x9'), (45.862315195521205, 'x1 x10'), (-559.74642834895849, 'x2^2'), (269.58094029167034, 'x2 x3'), (277.17683864785874, 'x2 x4'), (-164.43053530671779, 'x2 x5'), (135.28254416370959, 'x2 x6'), (257.28104923481806, 'x2 x7'), (79.284023612932231, 'x2 x8'), (19.85411431184087, 'x2 x9'), (151.18371130061919, 'x2 x10'), (5.4488887591251478, 'x3^2'), (174.44499204044325, 'x3 x4'), (189.81973447473823, 'x3 x5'), (511.25207294615291, 'x3 x6'), (276.06433942234673, 'x3 x7'), (69.810639086348274, 'x3 x8'), (0.51777937037970245, 'x3 x9'), (208.81499979197238, 'x3 x10'), (-133.84337042375896, 'x4^2'), (-114.42055123569273, 'x4 x5'), (312.06716922252116, 'x4 x6'), (-192.08138777115374, 'x4 x7'), (-149.13341407497882, 'x4 x8'), (20.35053869382666, 'x4 x9'), (-44.278827041120763, 'x4 x10'), (469.20523897868111, 'x5^2'), (101.87403733930796, 'x5 x6'), (30.620798925616285, 'x5 x7'), (2.2262691278095303, 'x5 x8'), (16.989283358284105, 'x5 x9'), (42.567877377353938, 'x5 x10'), (13.395166039113008, 'x6^2'), (106.04838087132492, 'x6 x7'), (-22.999736357563666, 'x6 x8'), (64.105584913656926, 'x6 x9'), (447.97785643152889, 'x6 x10'), (273.58226960403908, 'x7^2'), (-182.77474027166556, 'x7 x8'), (21.757808186436833, 'x7 x9'), (57.921651808454612, 'x7 x10'), (0.56758720826515585, 'x8^2'), (42.559967973934668, 'x8 x9'), (1.5455521456089514, 'x8 x10'), (0.065033516337627342, 'x9^2'), (16.718471485772227, 'x9 x10'), (-35.12803319846266, 'x10^2')]\n",
      "\n",
      "mse: 2.49037467275e-24\n",
      "r2: 1.0\n",
      "e. v.: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Here, we will use all the data as training data\n",
    "# Do the fit:\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get the model -- print the coefficients\n",
    "# print pipeline.named_steps['lm'].coef_\n",
    "# print(list(zip(pipeline.named_steps['lm'].coef_, input_names)))\n",
    "print 'model:'\n",
    "lm = pipeline.named_steps['lm']\n",
    "pf = pipeline.named_steps['pf']\n",
    "print zip(lm.coef_, pf.get_feature_names())\n",
    "print ''\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# Score the prediction\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print 'mse:', mean_squared_error(y, y_pred)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print 'r2:', r2_score(y, y_pred)\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "print 'e. v.:', explained_variance_score(y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "[(1.2224316003894842e-10, '1'), (-74.414916033031986, 'x0'), (27.688209758443683, 'x1'), (-457.81758727111156, 'x2'), (255.56352769659225, 'x3'), (-309.53699883871843, 'x4'), (62.397041026907473, 'x5'), (-756.04351457686778, 'x6'), (-163.1257226963711, 'x7'), (334.93023239955659, 'x8'), (9.30427611148823, 'x9'), (125.66413407261506, 'x10'), (147.5232503977459, 'x0^2'), (-5.7103096604015962, 'x0 x1'), (-254.86414492482558, 'x0 x2'), (-65.512928154817686, 'x0 x3'), (-133.40857478678768, 'x0 x4'), (-56.620154831703339, 'x0 x5'), (76.111546284019397, 'x0 x6'), (-249.81341759655822, 'x0 x7'), (467.03298622277487, 'x0 x8'), (-2.0852769655857442, 'x0 x9'), (-101.35182097297023, 'x0 x10'), (0.18355677109909563, 'x1^2'), (19.20227263470197, 'x1 x2'), (0.64291600196864929, 'x1 x3'), (21.53266644983518, 'x1 x4'), (20.194542063960437, 'x1 x5'), (82.74622001170421, 'x1 x6'), (23.807125692056797, 'x1 x7'), (73.586185212342585, 'x1 x8'), (0.064356375576167635, 'x1 x9'), (18.647850723041721, 'x1 x10'), (-273.71256026914051, 'x2^2'), (235.20014093397666, 'x2 x3'), (158.71577018989117, 'x2 x4'), (-154.59138828030089, 'x2 x5'), (133.68364267944378, 'x2 x6'), (136.55878923047271, 'x2 x7'), (145.64260283916275, 'x2 x8'), (7.0958903264837074, 'x2 x9'), (-206.97729263552355, 'x2 x10'), (5.8307620396936457, 'x3^2'), (170.44962725266095, 'x3 x4'), (176.27453115723154, 'x3 x5'), (536.93020251930614, 'x3 x6'), (251.53152437981362, 'x3 x7'), (125.45177528092103, 'x3 x8'), (0.20703406658992779, 'x3 x9'), (185.57076305380454, 'x3 x10'), (-130.74875440956322, 'x4^2'), (-20.605607063042086, 'x4 x5'), (304.09882177076105, 'x4 x6'), (-131.04275648045845, 'x4 x7'), (-167.24340796021863, 'x4 x8'), (7.5594256500299135, 'x4 x9'), (-24.837279193521866, 'x4 x10'), (302.90031758811642, 'x5^2'), (-67.665758225068757, 'x5 x6'), (181.88218261226348, 'x5 x7'), (157.28738708871541, 'x5 x8'), (6.6538862157926477, 'x5 x9'), (168.36120643656443, 'x5 x10'), (26.110055605958948, 'x6^2'), (230.22445823841571, 'x6 x7'), (-31.839429985331563, 'x6 x8'), (26.119344284789342, 'x6 x9'), (369.92719456116288, 'x6 x10'), (277.06087500169218, 'x7^2'), (-357.26531725226585, 'x7 x8'), (8.2036265425828514, 'x7 x9'), (73.154334315301568, 'x7 x10'), (6.5315025661840878, 'x8^2'), (20.224744609985933, 'x8 x9'), (-11.189116598530319, 'x8 x10'), (0.023468533301833787, 'x9^2'), (6.3584296792064903, 'x9 x10'), (118.20528043508892, 'x10^2')]\n",
      "\n",
      "mse: 13283.4727744\n",
      "r2: 0.0\n",
      "e. v.: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Now we'll split training and test data and see what that does.\n",
    "\n",
    "# Params:\n",
    "test_size = .01\n",
    "\n",
    "# Split:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "# Fit:\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get the model -- print the coefficients\n",
    "print 'model:'\n",
    "lm = pipeline.named_steps['lm']\n",
    "pf = pipeline.named_steps['pf']\n",
    "print zip(lm.coef_, pf.get_feature_names())\n",
    "print ''\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Score the prediction\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print 'mse:', mean_squared_error(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print 'r2:', r2_score(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "print 'e. v.:', explained_variance_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda2]",
   "language": "python",
   "name": "conda-env-miniconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
